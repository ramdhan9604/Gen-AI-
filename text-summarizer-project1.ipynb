{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T12:29:47.013150Z","iopub.execute_input":"2024-10-28T12:29:47.013935Z","iopub.status.idle":"2024-10-28T12:29:48.118182Z","shell.execute_reply.started":"2024-10-28T12:29:47.013891Z","shell.execute_reply":"2024-10-28T12:29:48.117270Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Mon Oct 28 12:29:47 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   53C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   55C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:30:15.364659Z","iopub.execute_input":"2024-10-28T13:30:15.365054Z","iopub.status.idle":"2024-10-28T13:30:15.372650Z","shell.execute_reply.started":"2024-10-28T13:30:15.365016Z","shell.execute_reply":"2024-10-28T13:30:15.371590Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q","metadata":{"execution":{"iopub.status.busy":"2024-10-28T12:36:03.469948Z","iopub.execute_input":"2024-10-28T12:36:03.470376Z","iopub.status.idle":"2024-10-28T12:36:21.007607Z","shell.execute_reply.started":"2024-10-28T12:36:03.470336Z","shell.execute_reply":"2024-10-28T12:36:21.006601Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade accelerate\n!pip uninstall -y transformers accelerate\n!pip install transformers accelerate","metadata":{"execution":{"iopub.status.busy":"2024-10-28T12:55:02.031447Z","iopub.execute_input":"2024-10-28T12:55:02.031836Z","iopub.status.idle":"2024-10-28T12:55:39.221503Z","shell.execute_reply.started":"2024-10-28T12:55:02.031799Z","shell.execute_reply":"2024-10-28T12:55:39.220313Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting accelerate\n  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\nSuccessfully installed accelerate-1.0.1\nFound existing installation: transformers 4.45.1\nUninstalling transformers-4.45.1:\n  Successfully uninstalled transformers-4.45.1\nFound existing installation: accelerate 1.0.1\nUninstalling accelerate-1.0.1:\n  Successfully uninstalled accelerate-1.0.1\nCollecting transformers\n  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate\n  Using cached accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hUsing cached accelerate-1.0.1-py3-none-any.whl (330 kB)\nInstalling collected packages: accelerate, transformers\nSuccessfully installed accelerate-1.0.1 transformers-4.46.0\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom transformers import pipeline, set_seed\nfrom datasets import load_dataset, load_from_disk\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nimport pandas as pd\n# from datasets import load_dataset, load_metric\n\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nfrom tqdm import tqdm\nimport torch\n\nnltk.download(\"punkt\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:05:12.428735Z","iopub.execute_input":"2024-10-28T13:05:12.429117Z","iopub.status.idle":"2024-10-28T13:05:12.583805Z","shell.execute_reply.started":"2024-10-28T13:05:12.429079Z","shell.execute_reply":"2024-10-28T13:05:12.582937Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:09:53.819447Z","iopub.execute_input":"2024-10-28T13:09:53.819851Z","iopub.status.idle":"2024-10-28T13:10:06.142638Z","shell.execute_reply.started":"2024-10-28T13:09:53.819812Z","shell.execute_reply":"2024-10-28T13:10:06.141497Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"model_ckpt = \"google/pegasus-cnn_dailymail\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:10:26.015112Z","iopub.execute_input":"2024-10-28T13:10:26.016084Z","iopub.status.idle":"2024-10-28T13:10:27.880615Z","shell.execute_reply.started":"2024-10-28T13:10:26.016039Z","shell.execute_reply":"2024-10-28T13:10:27.879791Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24afe29d7f8746e3b44d7549e2553600"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d9578f8127418880fcc5e475dd22e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6824f6ff7b574934b770f38694d53075"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adf2ebd64ed94d9da1c5e1f0011462aa"}},"metadata":{}}]},{"cell_type":"code","source":"model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:11:41.340260Z","iopub.execute_input":"2024-10-28T13:11:41.340649Z","iopub.status.idle":"2024-10-28T13:11:49.865285Z","shell.execute_reply.started":"2024-10-28T13:11:41.340610Z","shell.execute_reply":"2024-10-28T13:11:49.864545Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndataset_samsum = load_dataset(\"samsum\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:12:20.235778Z","iopub.execute_input":"2024-10-28T13:12:20.236169Z","iopub.status.idle":"2024-10-28T13:12:27.814559Z","shell.execute_reply.started":"2024-10-28T13:12:20.236131Z","shell.execute_reply":"2024-10-28T13:12:27.813824Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"samsum.py:   0%|          | 0.00/3.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7d5258220e45ecac52b8211308511e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f10a44d735446ba543c829308776fd"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for samsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/samsum.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"corpus.7z:   0%|          | 0.00/2.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7737b9590024d3fb05c8d4a37483b2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3daf859f6f0c4b8a989c168fb672ea1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"286b69fba6ea4b6e869e90261ada413a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575a50d3a0ac459482f94a2563f833e8"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_samsum","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:12:51.279031Z","iopub.execute_input":"2024-10-28T13:12:51.279873Z","iopub.status.idle":"2024-10-28T13:12:51.285849Z","shell.execute_reply.started":"2024-10-28T13:12:51.279835Z","shell.execute_reply":"2024-10-28T13:12:51.284965Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14732\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_samsum['train']['dialogue'][1]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:13:14.052164Z","iopub.execute_input":"2024-10-28T13:13:14.052525Z","iopub.status.idle":"2024-10-28T13:13:14.092529Z","shell.execute_reply.started":"2024-10-28T13:13:14.052493Z","shell.execute_reply":"2024-10-28T13:13:14.091569Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'Olivia: Who are you voting for in this election? \\r\\nOliver: Liberals as always.\\r\\nOlivia: Me too!!\\r\\nOliver: Great'"},"metadata":{}}]},{"cell_type":"code","source":"dataset_samsum['train'][1][\"summary\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:13:43.016242Z","iopub.execute_input":"2024-10-28T13:13:43.016679Z","iopub.status.idle":"2024-10-28T13:13:43.023314Z","shell.execute_reply.started":"2024-10-28T13:13:43.016639Z","shell.execute_reply":"2024-10-28T13:13:43.022378Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'Olivia and Olivier are voting for liberals in this election. '"},"metadata":{}}]},{"cell_type":"code","source":"\nsplit_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n\nprint(f\"Split lengths: {split_lengths}\")\nprint(f\"Features: {dataset_samsum['train'].column_names}\")\nprint(\"\\nDialogue:\")\n\nprint(dataset_samsum[\"test\"][1][\"dialogue\"])\n\nprint(\"\\nSummary:\")\n\nprint(dataset_samsum[\"test\"][1][\"summary\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:13:57.048390Z","iopub.execute_input":"2024-10-28T13:13:57.048766Z","iopub.status.idle":"2024-10-28T13:13:57.055218Z","shell.execute_reply.started":"2024-10-28T13:13:57.048731Z","shell.execute_reply":"2024-10-28T13:13:57.054296Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Split lengths: [14732, 819, 818]\nFeatures: ['id', 'dialogue', 'summary']\n\nDialogue:\nEric: MACHINE!\nRob: That's so gr8!\nEric: I know! And shows how Americans see Russian ;)\nRob: And it's really funny!\nEric: I know! I especially like the train part!\nRob: Hahaha! No one talks to the machine like that!\nEric: Is this his only stand-up?\nRob: Idk. I'll check.\nEric: Sure.\nRob: Turns out no! There are some of his stand-ups on youtube.\nEric: Gr8! I'll watch them now!\nRob: Me too!\nEric: MACHINE!\nRob: MACHINE!\nEric: TTYL?\nRob: Sure :)\n\nSummary:\nEric and Rob are going to watch a stand-up on youtube.\n","output_type":"stream"}]},{"cell_type":"code","source":"def convert_examples_to_features(example_batch):\n    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n\n    with tokenizer.as_target_tokenizer():\n        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n\n    return {\n        'input_ids' : input_encodings['input_ids'],\n        'attention_mask': input_encodings['attention_mask'],\n        'labels': target_encodings['input_ids']\n    }\n\n     ","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:14:51.348946Z","iopub.execute_input":"2024-10-28T13:14:51.349640Z","iopub.status.idle":"2024-10-28T13:14:51.355303Z","shell.execute_reply.started":"2024-10-28T13:14:51.349599Z","shell.execute_reply":"2024-10-28T13:14:51.354345Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:14:57.155165Z","iopub.execute_input":"2024-10-28T13:14:57.155549Z","iopub.status.idle":"2024-10-28T13:15:02.193794Z","shell.execute_reply.started":"2024-10-28T13:14:57.155510Z","shell.execute_reply":"2024-10-28T13:15:02.192805Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2245151898d44e2bba5d03850496f88"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb3cc4d6acdf40fcbdd52907cb4c96ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae6e5ea62df74c9a9a675ea6c4ad7cdc"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_samsum_pt[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:15:09.729364Z","iopub.execute_input":"2024-10-28T13:15:09.730070Z","iopub.status.idle":"2024-10-28T13:15:09.736647Z","shell.execute_reply.started":"2024-10-28T13:15:09.730029Z","shell.execute_reply":"2024-10-28T13:15:09.735549Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 14732\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_samsum_pt[\"train\"][\"input_ids\"][1]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:15:21.090628Z","iopub.execute_input":"2024-10-28T13:15:21.091016Z","iopub.status.idle":"2024-10-28T13:15:22.409802Z","shell.execute_reply.started":"2024-10-28T13:15:21.090968Z","shell.execute_reply":"2024-10-28T13:15:22.408868Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[18038,\n 151,\n 2632,\n 127,\n 119,\n 6228,\n 118,\n 115,\n 136,\n 2974,\n 152,\n 10463,\n 151,\n 35884,\n 130,\n 329,\n 107,\n 18038,\n 151,\n 2587,\n 314,\n 1242,\n 10463,\n 151,\n 1509,\n 1]"},"metadata":{}}]},{"cell_type":"code","source":"dataset_samsum_pt[\"train\"][\"attention_mask\"][1]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:15:33.558594Z","iopub.execute_input":"2024-10-28T13:15:33.559509Z","iopub.status.idle":"2024-10-28T13:15:34.815193Z","shell.execute_reply.started":"2024-10-28T13:15:33.559465Z","shell.execute_reply":"2024-10-28T13:15:34.814294Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"},"metadata":{}}]},{"cell_type":"code","source":"# Training \n\nfrom transformers import DataCollatorForSeq2Seq \n\n\nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:18:21.603351Z","iopub.execute_input":"2024-10-28T13:18:21.603766Z","iopub.status.idle":"2024-10-28T13:18:21.609101Z","shell.execute_reply.started":"2024-10-28T13:18:21.603727Z","shell.execute_reply":"2024-10-28T13:18:21.608056Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntrainer_args = TrainingArguments(\n    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n    weight_decay=0.01, logging_steps=10,\n    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n    gradient_accumulation_steps=16\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:23:31.668215Z","iopub.execute_input":"2024-10-28T13:23:31.668620Z","iopub.status.idle":"2024-10-28T13:23:32.851389Z","shell.execute_reply.started":"2024-10-28T13:23:31.668582Z","shell.execute_reply":"2024-10-28T13:23:32.850308Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrainer = Trainer(model=model_pegasus, args=trainer_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n                  train_dataset=dataset_samsum_pt[\"test\"],\n                  eval_dataset=dataset_samsum_pt[\"validation\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:23:48.237548Z","iopub.execute_input":"2024-10-28T13:23:48.238300Z","iopub.status.idle":"2024-10-28T13:23:49.948029Z","shell.execute_reply.started":"2024-10-28T13:23:48.238259Z","shell.execute_reply":"2024-10-28T13:23:49.947262Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3033698729.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(model=model_pegasus, args=trainer_args,\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:24:06.126040Z","iopub.execute_input":"2024-10-28T13:24:06.126982Z","iopub.status.idle":"2024-10-28T13:29:24.502623Z","shell.execute_reply.started":"2024-10-28T13:24:06.126938Z","shell.execute_reply":"2024-10-28T13:29:24.501674Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113743133334235, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae713b27ba9e4cc7a1da4593fe6317d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241028_132448-k4p5lkad</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prajapatramdhan2001-rp/huggingface/runs/k4p5lkad' target=\"_blank\">pegasus-samsum</a></strong> to <a href='https://wandb.ai/prajapatramdhan2001-rp/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prajapatramdhan2001-rp/huggingface' target=\"_blank\">https://wandb.ai/prajapatramdhan2001-rp/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prajapatramdhan2001-rp/huggingface/runs/k4p5lkad' target=\"_blank\">https://wandb.ai/prajapatramdhan2001-rp/huggingface/runs/k4p5lkad</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 04:21, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2816: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=25, training_loss=50.60422729492188, metrics={'train_runtime': 317.9151, 'train_samples_per_second': 2.576, 'train_steps_per_second': 0.079, 'total_flos': 423944250507264.0, 'train_loss': 50.60422729492188, 'epoch': 0.975609756097561})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluation\n\ndef generate_batch_sized_chunks(list_of_elements, batch_size):\n    \"\"\"split the dataset into smaller batches that we can process simultaneously\n    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\n\n\ndef calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n                               batch_size=16, device=device,\n                               column_text=\"article\",\n                               column_summary=\"highlights\"):\n    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n\n        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n                        padding=\"max_length\", return_tensors=\"pt\")\n\n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device),\n                         length_penalty=0.8, num_beams=8, max_length=128)\n        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n\n        # Finally, we decode the generated texts,\n        # replace the  token, and add the decoded texts with the references to the metric.\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n                                clean_up_tokenization_spaces=True)\n               for s in summaries]\n\n        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n\n\n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n\n    #  Finally compute and return the ROUGE scores.\n    score = metric.compute()\n    return score","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:30:23.427887Z","iopub.execute_input":"2024-10-28T13:30:23.428908Z","iopub.status.idle":"2024-10-28T13:30:23.441374Z","shell.execute_reply.started":"2024-10-28T13:30:23.428852Z","shell.execute_reply":"2024-10-28T13:30:23.440414Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from evaluate import load \n\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\nrouge_metric = load('rouge')\n     ","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:30:55.580350Z","iopub.execute_input":"2024-10-28T13:30:55.581236Z","iopub.status.idle":"2024-10-28T13:30:56.093613Z","shell.execute_reply.started":"2024-10-28T13:30:55.581195Z","shell.execute_reply":"2024-10-28T13:30:56.092806Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae7e85ea17b04719aa93274fc8f72b6a"}},"metadata":{}}]},{"cell_type":"code","source":"score = calculate_metric_on_test_ds(\n    dataset_samsum['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n)\n\nrouge_dict = dict((rn, score[rn] ) for rn in rouge_names )\n\npd.DataFrame(rouge_dict, index = [f'pegasus'] )","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:42:25.668159Z","iopub.execute_input":"2024-10-28T13:42:25.668519Z","iopub.status.idle":"2024-10-28T13:42:44.582575Z","shell.execute_reply.started":"2024-10-28T13:42:25.668486Z","shell.execute_reply":"2024-10-28T13:42:44.581697Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"100%|██████████| 5/5 [00:18<00:00,  3.72s/it]\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"           rouge1  rouge2    rougeL  rougeLsum\npegasus  0.017392     0.0  0.017401   0.017217","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pegasus</th>\n      <td>0.017392</td>\n      <td>0.0</td>\n      <td>0.017401</td>\n      <td>0.017217</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Save model\nmodel_pegasus.save_pretrained(\"pegasus-samsum-model\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:47:15.037399Z","iopub.execute_input":"2024-10-28T13:47:15.038436Z","iopub.status.idle":"2024-10-28T13:47:19.724859Z","shell.execute_reply.started":"2024-10-28T13:47:15.038391Z","shell.execute_reply":"2024-10-28T13:47:19.724056Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\n## Save tokenizer\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:47:29.635291Z","iopub.execute_input":"2024-10-28T13:47:29.635689Z","iopub.status.idle":"2024-10-28T13:47:29.672508Z","shell.execute_reply.started":"2024-10-28T13:47:29.635652Z","shell.execute_reply":"2024-10-28T13:47:29.671628Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/spiece.model',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"#Load\n\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:48:29.753556Z","iopub.execute_input":"2024-10-28T13:48:29.754258Z","iopub.status.idle":"2024-10-28T13:48:29.924320Z","shell.execute_reply.started":"2024-10-28T13:48:29.754214Z","shell.execute_reply":"2024-10-28T13:48:29.923519Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#Prediction\n\ngen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n\n\n\nsample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n\nreference = dataset_samsum[\"test\"][0][\"summary\"]\n\npipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n\n##\nprint(\"Dialogue:\")\nprint(sample_text)\n\n\nprint(\"\\nReference Summary:\")\nprint(reference)\n\n\nprint(\"\\nModel Summary:\")\nprint(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T13:48:36.870355Z","iopub.execute_input":"2024-10-28T13:48:36.870767Z","iopub.status.idle":"2024-10-28T13:48:57.217250Z","shell.execute_reply.started":"2024-10-28T13:48:36.870726Z","shell.execute_reply":"2024-10-28T13:48:57.216340Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\nYour max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n","output_type":"stream"},{"name":"stdout","text":"Dialogue:\nHannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nHannah: <file_gif>\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nHannah: <file_gif>\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him 🙂\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n\nReference Summary:\nHannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n\nModel Summary:\nAmanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}